{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This set of news sources was taken as a representative sample originally. We cast a wider net in a different\n",
    "# version later in this nb\n",
    "\n",
    "# list of national news sources confirmed to be in API\n",
    "national_news_list = ['huffpost.com',  'politico.com', \n",
    "                      'time.com', 'msnbc.com',  'cbsnews.com',\n",
    "                     'latimes.com', 'washingtonpost.com','cnn.com', \n",
    "                      'breitbart.com','usatoday.com', \n",
    "                      'foxnews.com','wsj.com','nbcnews.com',\n",
    "                     'bloomberg.com','npr.org']\n",
    "\n",
    "# list of local news sources confirmed to be in the API\n",
    "regional_news_df = pd.read_csv('regional_news/top_regional_newspapers_clean.csv', index_col = 0)\n",
    "\n",
    "regional_domains = []\n",
    "\n",
    "for index, row in regional_news_df[regional_news_df['in_api_flag'] == 1].iterrows():\n",
    "    regional_domains.append(row['url'])\n",
    "\n",
    "# combine the two lists\n",
    "for source in regional_domains:\n",
    "    if(source not in national_news_list):\n",
    "        national_news_list.append(source)\n",
    "        \n",
    "the_list = national_news_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paid API Key version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API loop\n",
    "news_api_key = '######################'\n",
    "\n",
    "\n",
    "# build the endpoint query\n",
    "query = 'covid%20OR%20coronavirus'\n",
    "year = \"2020\"\n",
    "month = 12\n",
    "startday = 1\n",
    "endday = 30\n",
    "\n",
    "full_start =\"{}-{}-{}\".format(year, month, startday)\n",
    "full_end = \"{}-{}-{}\".format(year, month, endday)\n",
    "\n",
    "dir_name = \"news_dfs_{month}.{start}_{month}.{end}\".format(month = month, start = startday, end = endday)\n",
    "\n",
    "# makes the local folder if it doesn't exist\n",
    "if not os.path.isdir(dir_name):\n",
    "    os.mkdir(dir_name)\n",
    "\n",
    "total_calls = 0\n",
    "total_items = 0\n",
    "# loops through each URL    \n",
    "for item in the_list:\n",
    "    print(item)\n",
    "    domain = item\n",
    "    superdata = pd.DataFrame(columns=['title', 'description', 'url', 'publishedAt', 'content', 'source'])\n",
    "    i = 1\n",
    "    check = True\n",
    "    while check:\n",
    "        endpoint1 = \"http://newsapi.org/v2/everything?q={query}&domains={domain}&from={date}\".format(query = query, domain = domain, date = full_start) + \"T00:00:00&to={date}\".format(date = full_end) + \"T23:59:59&language=en&pageSize=100&page={page_num}&apiKey={key}\".format(query = query, page_num = i, key = news_api_key)\n",
    "        print(endpoint1)\n",
    "\n",
    "        news1 = requests.get(endpoint1)\n",
    "        formatted_news1 = news1.json() \n",
    "\n",
    "        formatted_news1 = formatted_news1['articles']\n",
    "        \n",
    "        # for checking purposes\n",
    "        total_calls = total_calls + 1\n",
    "        \n",
    "        # breaks loop if there are no more articles\n",
    "        if not formatted_news1:\n",
    "            print(\"no more articles for {}\".format(domain))\n",
    "            break\n",
    "            \n",
    "        for j, article in enumerate(formatted_news1):\n",
    "            title = article['title']\n",
    "            description = article['description']\n",
    "            url = article['url']\n",
    "            publishedAt = article['publishedAt']\n",
    "            content = article['content']\n",
    "            source = article['source'].get('name')\n",
    "\n",
    "            temp = pd.DataFrame({'title': title, 'description': description, 'url':url, 'publishedAt':publishedAt,\n",
    "                             'content':content, 'source':source}, index = [j])\n",
    "            superdata = superdata.append(temp, ignore_index = True)\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # increments page number\n",
    "        i = i+1\n",
    "    print(\"Writing {}\".format(item))\n",
    "    superdata.to_csv(dir_name + \"/news_{domain}_{month}.{start}_{month}.{end}.csv\".format(domain = domain, month = month, start = startday, end = endday), encoding = \"utf-8\")\n",
    "    \n",
    "    # for check at end\n",
    "    total_items = total_items + 1\n",
    "    #the_list.remove(item)\n",
    "\n",
    "print(\"total_calls: {}\".format(total_calls))\n",
    "print(\"total_domains: {}\".format(total_items))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the widest possible net, querying for any mention of covid/coronavirus over all articles \n",
    "# available in the API. The only thing that needs to be changed is the month and date range\n",
    "# This cell writes out 4 chunks for each day \n",
    "month = 12\n",
    "for i in range(1,31):\n",
    "    \n",
    "    news_api_key = '######################' \n",
    "\n",
    "\n",
    "    # build the endpoint query\n",
    "    query = 'covid%20OR%20coronavirus'\n",
    "    year = \"2020\"\n",
    "\n",
    "    startday = endday = i\n",
    "\n",
    "\n",
    "\n",
    "    full_start =\"{}-{}-{}\".format(year, month, startday)\n",
    "    full_end = \"{}-{}-{}\".format(year, month, endday)\n",
    "\n",
    "    dir_name = \"fullset\"\n",
    "\n",
    "    # makes the local folder if it doesn't exist\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "    total_calls = 0\n",
    "    total_items = 0\n",
    "    # loops through each URL    \n",
    "\n",
    "    superdata = pd.DataFrame(columns=['title', 'description', 'url', 'publishedAt', 'content', 'source'])\n",
    "    i = 1\n",
    "    check = True\n",
    "    while check:\n",
    "        endpoint1 = \"http://newsapi.org/v2/everything?q={query}&from={date}\".format(query = query, domain = domain, date = full_start) + \"T00:00:00&to={date}\".format(date = full_end) + \"T11:29:59&language=en&pageSize=100&page={page_num}&apiKey={key}\".format(query = query, page_num = i, key = news_api_key)\n",
    "        print(endpoint1)\n",
    "\n",
    "        news1 = requests.get(endpoint1)\n",
    "        formatted_news1 = news1.json()\n",
    "        print(formatted_news1['totalResults'])\n",
    "        if(formatted_news1['totalResults'] >=9900):        \n",
    "            print(\"total results greater than 9900, redo dates\")\n",
    "            break\n",
    "\n",
    "        formatted_news1 = formatted_news1['articles']\n",
    "\n",
    "\n",
    "        # for checking purposes\n",
    "        total_calls = total_calls + 1\n",
    "\n",
    "\n",
    "        # breaks loop if there are no more articles\n",
    "        if not formatted_news1:\n",
    "            print(\"no more articles\")\n",
    "            break\n",
    "\n",
    "        for j, article in enumerate(formatted_news1):\n",
    "            source = article['source'].get('name')\n",
    "            if source in list_of_domains:\n",
    "                continue\n",
    "            title = article['title']\n",
    "            description = article['description']\n",
    "            url = article['url']\n",
    "            publishedAt = article['publishedAt']\n",
    "            content = article['content']\n",
    "\n",
    "            temp = pd.DataFrame({'title': title, 'description': description, 'url':url, 'publishedAt':publishedAt,\n",
    "                             'content':content, 'source':source}, index = [j])\n",
    "            superdata = superdata.append(temp, ignore_index = True)\n",
    "\n",
    "\n",
    "        time.sleep(.2)\n",
    "\n",
    "        # increments page number\n",
    "        i = i+1\n",
    "    print(\"Writing\")\n",
    "    superdata.to_csv(dir_name + \"/news_{month}.{start}_{month}.{end}_fullset_p1.csv\".format(domain = domain, month = month, start = startday, end = endday), encoding = \"utf-8\")\n",
    "\n",
    "    # for check at end\n",
    "\n",
    "    print(\"total_calls: {}\".format(total_calls))\n",
    "\n",
    "\n",
    "    # second part\n",
    "    superdata1 = pd.DataFrame(columns=['title', 'description', 'url', 'publishedAt', 'content', 'source'])\n",
    "    i = 1\n",
    "    check = True\n",
    "    while check:\n",
    "        endpoint1 = \"http://newsapi.org/v2/everything?q={query}&from={date}\".format(query = query, domain = domain, date = full_start) + \"T11:30:00&to={date}\".format(date = full_end) + \"T15:59:59&language=en&pageSize=100&page={page_num}&apiKey={key}\".format(query = query, page_num = i, key = news_api_key)\n",
    "        print(endpoint1)\n",
    "\n",
    "        news1 = requests.get(endpoint1)\n",
    "        formatted_news1 = news1.json()\n",
    "        print(formatted_news1['totalResults'])\n",
    "        if(formatted_news1['totalResults'] >=9900):\n",
    "\n",
    "            print(\"total results greater than 9900, redo dates\")\n",
    "            break\n",
    "\n",
    "        formatted_news1 = formatted_news1['articles']\n",
    "\n",
    "\n",
    "        # for checking purposes\n",
    "        total_calls = total_calls + 1\n",
    "\n",
    "\n",
    "        # breaks loop if there are no more articles\n",
    "        if not formatted_news1:\n",
    "            print(\"no more articles\")\n",
    "            break\n",
    "\n",
    "        for j, article in enumerate(formatted_news1):\n",
    "            source = article['source'].get('name')\n",
    "            if source in list_of_domains:\n",
    "                continue\n",
    "            title = article['title']\n",
    "            description = article['description']\n",
    "            url = article['url']\n",
    "            publishedAt = article['publishedAt']\n",
    "            content = article['content']\n",
    "\n",
    "            temp = pd.DataFrame({'title': title, 'description': description, 'url':url, 'publishedAt':publishedAt,\n",
    "                             'content':content, 'source':source}, index = [j])\n",
    "            superdata1 = superdata1.append(temp, ignore_index = True)\n",
    "\n",
    "\n",
    "        time.sleep(.2)\n",
    "\n",
    "        # increments page number\n",
    "        i = i+1\n",
    "    print(\"Writing\")\n",
    "    superdata1.to_csv(dir_name + \"/news_{month}.{start}_{month}.{end}_fullset_p2.csv\".format(domain = domain, month = month, start = startday, end = endday), encoding = \"utf-8\")\n",
    "\n",
    "    print(\"total_calls: {}\".format(total_calls))\n",
    "    # third part\n",
    "    superdata2 = pd.DataFrame(columns=['title', 'description', 'url', 'publishedAt', 'content', 'source'])\n",
    "    i = 1\n",
    "    check = True\n",
    "    while check:\n",
    "        endpoint1 = \"http://newsapi.org/v2/everything?q={query}&from={date}\".format(query = query, domain = domain, date = full_start) + \"T16:00:00&to={date}\".format(date = full_end) + \"T20:59:59&language=en&pageSize=100&page={page_num}&apiKey={key}\".format(query = query, page_num = i, key = news_api_key)\n",
    "        print(endpoint1)\n",
    "\n",
    "        news1 = requests.get(endpoint1)\n",
    "        formatted_news1 = news1.json()\n",
    "        print(formatted_news1['totalResults'])\n",
    "        if(formatted_news1['totalResults'] >=9900):\n",
    "\n",
    "            print(\"total results greater than 9900, redo dates\")\n",
    "            break\n",
    "\n",
    "        formatted_news1 = formatted_news1['articles']\n",
    "\n",
    "\n",
    "        # for checking purposes\n",
    "        total_calls = total_calls + 1\n",
    "\n",
    "\n",
    "        # breaks loop if there are no more articles\n",
    "        if not formatted_news1:\n",
    "            print(\"no more articles\")\n",
    "            break\n",
    "\n",
    "        for j, article in enumerate(formatted_news1):\n",
    "            source = article['source'].get('name')\n",
    "            if source in list_of_domains:\n",
    "                continue\n",
    "            title = article['title']\n",
    "            description = article['description']\n",
    "            url = article['url']\n",
    "            publishedAt = article['publishedAt']\n",
    "            content = article['content']\n",
    "\n",
    "            temp = pd.DataFrame({'title': title, 'description': description, 'url':url, 'publishedAt':publishedAt,\n",
    "                             'content':content, 'source':source}, index = [j])\n",
    "            superdata2 = superdata2.append(temp, ignore_index = True)\n",
    "\n",
    "\n",
    "        time.sleep(.2)\n",
    "\n",
    "        # increments page number\n",
    "        i = i+1\n",
    "    print(\"Writing\")\n",
    "    superdata2.to_csv(dir_name + \"/news_{month}.{start}_{month}.{end}_fullset_p3.csv\".format(domain = domain, month = month, start = startday, end = endday), encoding = \"utf-8\")\n",
    "\n",
    "\n",
    "    # for check at end\n",
    "\n",
    "    print(\"total_calls: {}\".format(total_calls))\n",
    "\n",
    "    # fourth part\n",
    "    superdata3 = pd.DataFrame(columns=['title', 'description', 'url', 'publishedAt', 'content', 'source'])\n",
    "    i = 1\n",
    "    check = True\n",
    "    while check:\n",
    "        endpoint1 = \"http://newsapi.org/v2/everything?q={query}&from={date}\".format(query = query, domain = domain, date = full_start) + \"T21:00:00&to={date}\".format(date = full_end) + \"T23:59:59&language=en&pageSize=100&page={page_num}&apiKey={key}\".format(query = query, page_num = i, key = news_api_key)\n",
    "        print(endpoint1)\n",
    "\n",
    "        news1 = requests.get(endpoint1)\n",
    "        formatted_news1 = news1.json()\n",
    "        print(formatted_news1['totalResults'])\n",
    "        if(formatted_news1['totalResults'] >=9900):\n",
    "\n",
    "            print(\"total results greater than 9900, redo dates\")\n",
    "            break\n",
    "\n",
    "        formatted_news1 = formatted_news1['articles']\n",
    "\n",
    "\n",
    "        # for checking purposes\n",
    "        total_calls = total_calls + 1\n",
    "\n",
    "\n",
    "        # breaks loop if there are no more articles\n",
    "        if not formatted_news1:\n",
    "            print(\"no more articles\")\n",
    "            break\n",
    "\n",
    "        for j, article in enumerate(formatted_news1):\n",
    "            source = article['source'].get('name')\n",
    "            if source in list_of_domains:\n",
    "                continue\n",
    "            title = article['title']\n",
    "            description = article['description']\n",
    "            url = article['url']\n",
    "            publishedAt = article['publishedAt']\n",
    "            content = article['content']\n",
    "\n",
    "            temp = pd.DataFrame({'title': title, 'description': description, 'url':url, 'publishedAt':publishedAt,\n",
    "                             'content':content, 'source':source}, index = [j])\n",
    "            superdata3 = superdata3.append(temp, ignore_index = True)\n",
    "\n",
    "\n",
    "        time.sleep(.2)\n",
    "\n",
    "        # increments page number\n",
    "        i = i+1\n",
    "    print(\"Writing\")\n",
    "    superdata3.to_csv(dir_name + \"/news_{month}.{start}_{month}.{end}_fullset_p4.csv\".format(domain = domain, month = month, start = startday, end = endday), encoding = \"utf-8\")\n",
    "\n",
    "\n",
    "    # for check at end\n",
    "\n",
    "    print(\"total_calls: {}\".format(total_calls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
